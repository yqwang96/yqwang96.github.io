---
title: 'LangChain多知识库同时检索时filter不生效BUG的解决办法 Part2'
date: 2024-09-19
permalink: /cnposts/2024/09/blog-post-15/
tags:
  - Bug analysis
  - Code-sharing
---

昨天，通过在HTTP请求头Headers中携带参数的方法，解决了Langserve传参不生效的BUG。但是该方法的弊端在于——Headers信息在http请求中是明文发送的，会被其他人看到或是篡改。虽然这涉及不到一些核心内容，但是还是存在不安全因素和隐患。

为此，今天深入研究了Langserve源码，研究在传递参数的时候，框架到底是如何处理的，并通过其他方法实现在post请求发送的data中携带参数，而非在headers中，增强了数据安全性。

具体地说，在add_routes后，langserve将chain封装为APIHandler类。在这个类中，实现了invoke等API接口。其中，invoke接口将用户的request转发给下述的方法。该方法中的config_hash、server_config无法由用户指定。如果想要修改的话，应该要对langserve的源代码进行重写。

```python
async def invoke(
        self,
        request: Request,
        *,
        config_hash: str = "",
        server_config: Optional[RunnableConfig] = None,
    ) -> Response:
        """Invoke the runnable with the given input and config.

        Args:
            request: The request object.
            config_hash: A compressed representation of a config. Optionally
                         sent from the client side. This config must be validated.
            server_config: optional server configuration that will be merged
                with any other configuration. It's the last to be written, so
                it will override any other configuration.
        """
        # We do not use the InvokeRequest model here since configurable runnables
        # have dynamic schema -- so the validation below is a bit more involved.
        config, input_ = await self._get_config_and_input(
            request,
            config_hash,
            endpoint="invoke",
            server_config=server_config,
        )
        run_id = config["run_id"]

        event_aggregator = AsyncEventAggregatorCallback()
        _add_callbacks(config, [event_aggregator])

        ...
```

在上面这部分代码中，langserve首先对输入的config信息通过`_get_config_and_input`函数进行整合。在这个函数中，用户的输入通过一个验证类进行解析，判断输入格式是否符合要求。

`body = InvokeRequestShallowValidator.model_validate(body)`

在验证后，将进行解析和格式验证。解析的关键部分代码如下，可以看出，用户能够给定的config类型是str、dict或者BaseModel类型。一般来说，通过json发送的config信息在这里都相当于是dict。但是langserve此时无法解析出config的类型。原因在于langserve采用pydantic进行格式验证（即下述代码中的model变量）。但是，model的schema构建是受APIHandler的`self._config_specs`变量影响，而默认该变量为空列表，所以无法创建schema。

```python
    config_dicts = []
    for config in client_sent_configs:
        if isinstance(config, str):
            config_dicts.append(model(**_config_from_hash(config)).model_dump())
        elif isinstance(config, BaseModel):
            config_dicts.append(config.model_dump())
        elif isinstance(config, Mapping):
            config_dicts.append(model(**config).model_dump())
        else:
            raise TypeError(f"Expected a string, dict or BaseModel got {type(config)}")
    config = merge_configs(*config_dicts)
```

为此，用户需要重写`self._config_specs`和增加自定义的configurable的schema。修改后的`WebChain`如下所示

```python
from typing import Optional, Any, Type, List, Dict
from langchain.retrievers import EnsembleRetriever
from langchain_core.runnables import ConfigurableField
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.runnables import RunnableConfig, Runnable, RunnableBinding, RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.utils import Input, Output
from langchain_milvus import Milvus


class ConfigurableFieldSpec:
    def __init__(self, id: str, annotation: type, default: Any, name: str, description: str):
        self.id = id
        self.annotation = annotation
        self.default = default
        self.name = name
        self.description = description


class WebChain(Runnable):
    def __init__(self):
        super().__init__()
        self._config_specs = [
            ConfigurableFieldSpec(
                id="search_kwargs",
                annotation=Dict[str, Any],  # Expecting a dictionary
                default={},  # Default value as an empty dictionary
                name="Search Arguments",
                description="Parameters for search query."
            )
        ]

        self.milvus_config = {
            "host": "localhost",
            "port": 19530,
            "db_name": "default"
        }

        self.llm = llm

        self.embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L6-v2")

    @property
    def config_specs(self) -> List[ConfigurableFieldSpec]:
        """Override the config_specs to return the custom specs."""
        return self._config_specs

    def get_chain(self):
        collection_name_list = ['Default_0', 'Default_1']  # 从数据库中读取配置

        vectorstore_list = [
            Milvus(
                connection_args=self.milvus_config, embedding_function=self.embeddings, collection_name=collection_name
            ) for collection_name in collection_name_list
        ]

        retriever_list = [single_vectorstore.as_retriever().configurable_fields(
            search_kwargs=ConfigurableField(
                id="search_kwargs",
                name="doc's search_kwargs",
                description="doc's search_kwargs"
            )
        ) for single_vectorstore in vectorstore_list]

        # retriever_list = [single_vectorstore.as_retriever() for single_vectorstore in vectorstore_list]

        ensemble_retriever = EnsembleRetriever(
            retrievers=retriever_list, weights=[1 / len(retriever_list) for _ in range(len(retriever_list))]
        )

        template = """Answer the question based only on the following context:
        {context}
        Question: {question}
        """
        prompt = ChatPromptTemplate.from_template(template)
        chain = {"context": ensemble_retriever, 'question': RunnablePassthrough()} | prompt | self.llm
        return chain

    def invoke(
        self, input: Input, config: Optional[RunnableConfig] = None, **kwargs: Any
    ) -> Output:
        print(input)
        print(config)
        chain = self.get_chain()
        mes = chain.invoke(input, config=config)
        return mes
```

相应地，requests请求方法如下
```python
import requests
from langchain.globals import set_verbose, set_debug

set_verbose(True)
set_debug(True)

query = "What impact does the education level of older workers have on the labor market?"

url = f"http://localhost:8002/rag/invoke"

json1 = {
    'input': query,
    'config': {
        "configurable": {
            "search_kwargs": {
                "expr": "collection_name == 'Default_1'"
            }
        }
    }
}

response = requests.post(url, json=json1)

# 打印返回的结果
if response.status_code == 200:
    print("Response:")
    print(response.json())
else:
    print(f"Failed with status code: {response.status_code}")
    print(response.text)
```

通过这一方法，能够在json中直接发送configuration信息，无需担心暴露给第三方或是被第三方篡改。

------
